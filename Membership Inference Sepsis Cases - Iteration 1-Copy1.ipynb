{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff37860d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f102c3bb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run experiments/optimize_params.py \"bpic2011\" \"output\" \"10\" \"single\" \"laststate\" \"xgboost\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d84d6c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julia\\anaconda3\\envs\\PyCharm_projects\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:14:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "pipeline fitted\n",
      "Flag: Iterations num 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julia\\anaconda3\\envs\\PyCharm_projects\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:14:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "pipeline fitted\n",
      "Flag: Iterations num 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julia\\anaconda3\\envs\\PyCharm_projects\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:15:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "pipeline fitted\n",
      "Flag: Iterations num 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julia\\anaconda3\\envs\\PyCharm_projects\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:16:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "pipeline fitted\n",
      "Flag: Iterations num 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julia\\anaconda3\\envs\\PyCharm_projects\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:17:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "pipeline fitted\n",
      "Flag: Iterations num 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julia\\anaconda3\\envs\\PyCharm_projects\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:17:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "pipeline fitted\n",
      "Flag: Iterations num 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julia\\anaconda3\\envs\\PyCharm_projects\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:18:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "pipeline fitted\n",
      "Flag: Iterations num 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julia\\anaconda3\\envs\\PyCharm_projects\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:19:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "pipeline fitted\n",
      "Flag: Iterations num 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julia\\anaconda3\\envs\\PyCharm_projects\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:20:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "pipeline fitted\n",
      "Flag: Iterations num 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julia\\anaconda3\\envs\\PyCharm_projects\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:21:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "pipeline fitted\n",
      "Flag: Iterations num 9\n",
      "**************Flag: Writing Regression to the mean results forbpic2011_f5******************\n",
      "confidenceList\n",
      "[0.962824821472168, 0.9012563228607178, 0.9455811977386475, 0.9591202735900879, 0.9041502475738525, 0.9246960878372192, 0.9234987497329712, 0.8782428503036499, 0.9464155435562134, 0.9311971664428711, 0.9234987497329712, 0.9234987497329712, 0.90720534324646, 0.9012563228607178, 0.9012563228607178, 0.19883716106414795, 0.26662999391555786, 0.26662999391555786, 0.26662999391555786, 0.26662999391555786, 0.26662999391555786, 0.26662999391555786, 0.26662999391555786, 0.17200124263763428, 0.13085436820983887, 0.13890236616134644, 0.3095773458480835, 0.13890236616134644, 0.23606306314468384, 0.26662999391555786, 0.26662999391555786, 0.26662999391555786, 0.26662999391555786, 0.26662999391555786, 0.26662999391555786, 0.26662999391555786, 0.26662999391555786, 0.29352867603302, 0.26662999391555786, 0.1567457914352417, 0.5563897788524628, 0.3363736867904663, 0.13890236616134644, 0.26662999391555786, 0.26662999391555786, 0.9560829401016235, 0.9531904458999634, 0.9531904458999634, 0.7409998178482056, 0.8823915719985962, 0.9718014001846313, 0.962963342666626, 0.9523296356201172, 0.9333033561706543, 0.9477713108062744, 0.9560829401016235, 0.9560829401016235, 0.9560829401016235, 0.9531904458999634, 0.9531904458999634, 0.9531904458999634, 0.9531904458999634, 0.9531904458999634, 0.9531904458999634, 0.9531904458999634, 0.9380608797073364, 0.9380608797073364, 0.9531904458999634, 0.9531904458999634, 0.7159696817398071, 0.9380608797073364, 0.9531904458999634, 0.9531904458999634, 0.9531904458999634, 0.9531904458999634, 0.9531904458999634, 0.9380608797073364, 0.9246838763356209, 0.9820256698876619, 0.9742200281471014, 0.951291773468256, 0.9808834306895733, 0.9669287316501141, 0.9289604425430298, 0.982411490753293, 0.9878184674307704, 0.9709830917418003, 0.9886810900643468, 0.9803620520979166, 0.9756559673696756, 0.9864179817959666, 0.9739693496376276, 0.1060287356376648, 0.5398082137107849, 0.3912922739982605, 0.09649777412414551, 0.5168050825595856, 0.2861611843109131, 0.5041172802448273, 0.17110025882720947, 0.8692523241043091, 0.7678425312042236, 0.42296290397644043, 0.8092857599258423, 0.6426311731338501, 0.7820414304733276, 0.7129007577896118, 0.7521300315856934, 0.5958207845687866, 0.7678425312042236, 0.5598340034484863, 0.9177914410829544, 0.8837272301316261, 0.9312089681625366, 0.9073835611343384, 0.21662330627441406, 0.950153112411499, 0.9609507322311401, 0.9591275453567505, 0.9464247226715088, 0.904166579246521, 0.8969411849975586, 0.912980318069458, 0.912980318069458, 0.912980318069458, 0.912980318069458, 0.9073835611343384, 0.9073835611343384, 0.9073835611343384, 0.9073835611343384, 0.9073835611343384, 0.9073835611343384, 0.3775349259376526, 0.6724348068237305, 0.6724348068237305, 0.9073835611343384, 0.48831355571746826, 0.48831355571746826, 0.19471955299377441, 0.9718759581446648, 0.9718759581446648, 0.9718759581446648, 0.9956566276960075, 0.9073835611343384, 0.9073835611343384, 0.9073835611343384, 0.9073835611343384, 0.8667886257171631, 0.9073835611343384, 0.9342657327651978, 0.4441629648208618, 0.4441629648208618, 0.4441629648208618, 0.33102476596832275, 0.45157283544540405, 0.4870646595954895, 0.2243233323097229, 0.2243233323097229, 0.2243233323097229, 0.2243233323097229, 0.9264929294586182, 0.2243233323097229, 0.2243233323097229, 0.2243233323097229, 0.2243233323097229, 0.2243233323097229, 0.2243233323097229, 0.8938973173499107, 0.46291226148605347, 0.8938973173499107, 0.8938973173499107, 0.734642505645752, 0.2243233323097229, 0.2243233323097229, 0.2243233323097229, 0.46291226148605347, 0.8353531211614609, 0.8353531211614609, 0.8353531211614609, 0.480663537979126, 0.3597604036331177, 0.33102476596832275, 0.6780974864959717, 0.6022480726242065, 0.45071864128112793, 0.9986097812652588, 0.9983865022659302, 0.9927154779434204, 0.9982606172561646, 0.9989174604415894, 0.9991856813430786, 0.9989255666732788, 0.9980363845825195, 0.9981949329376221, 0.9984884262084961, 0.9984884262084961, 0.9984884262084961, 0.9984884262084961, 0.9983865022659302, 0.9983865022659302, 0.9983865022659302, 0.9983865022659302, 0.9983865022659302, 0.9983865022659302, 0.9983865022659302, 0.9983865022659302, 0.9983865022659302, 0.9983865022659302, 0.9983865022659302, 0.9983865022659302, 0.9983865022659302, 0.9983865022659302, 0.9983865022659302, 0.8930215835571289, 0.9891172647476196, 0.9891172647476196, 0.9126605987548828, 0.9918099641799927, 0.9892085790634155, 0.9860566854476929, 0.9867690801620483, 0.9878314733505249, 0.9898014068603516, 0.9898014068603516, 0.9898014068603516, 0.9898014068603516, 0.9891172647476196, 0.9891172647476196, 0.9891172647476196, 0.9891172647476196, 0.9891172647476196, 0.9891172647476196, 0.9891172647476196, 0.9891172647476196, 0.9891172647476196, 0.9891172647476196, 0.33984100818634033, 0.9891172647476196, 0.9891172647476196, 0.9891172647476196, 0.9891172647476196, 0.9891172647476196, 0.9891172647476196, 0.58834308385849, 0.7453906238079071, 0.46966058015823364, 0.4867727756500244, 0.3219159245491028, 0.3737694025039673, 0.4695631265640259, 0.8061986863613129, 0.7324172854423523, 0.6475155055522919, 0.849486693739891, 0.674028217792511, 0.588762104511261, 0.6719752252101898, 0.7367129623889923, 0.7573972791433334, 0.7169254124164581, 0.7169254124164581, 0.7169254124164581, 0.7169254124164581, 0.7324172854423523, 0.7324172854423523, 0.7324172854423523, 0.7324172854423523, 0.7324172854423523, 0.7324172854423523, 0.7324172854423523, 0.7324172854423523, 0.8483149260282516, 0.7324172854423523, 0.6027779579162598, 0.6027779579162598, 0.8875144049525261, 0.8875144049525261, 0.8875144049525261, 0.8875144049525261, 0.8875144049525261, 0.7324172854423523, 0.7324172854423523, 0.7324172854423523, 0.7324172854423523, 0.7324172854423523, 0.7324172854423523, 0.12147712707519531, 0.047503113746643066, 0.2869008183479309, 0.21987533569335938, 0.005569815635681152, 0.3709838390350342, 0.24585533142089844, 0.05069708824157715, 0.00862109661102295, 0.07999944686889648, 0.07999944686889648, 0.07999944686889648, 0.07999944686889648, 0.047503113746643066, 0.047503113746643066, 0.047503113746643066, 0.047503113746643066, 0.047503113746643066, 0.047503113746643066, 0.047503113746643066, 0.06422311067581177, 0.06422311067581177, 0.047503113746643066, 0.44446855783462524, 0.44446855783462524, 0.9559153728187084, 0.9559153728187084, 0.9153630658984184, 0.9056820720434189, 0.9056820720434189, 0.047503113746643066, 0.047503113746643066, 0.047503113746643066, 0.047503113746643066, 0.09608274698257446, 0.047503113746643066, 0.4290109872817993, 0.3218576908111572, 0.26187896728515625, 0.974865198135376, 0.7376589775085449, 0.9856700897216797, 0.9266420602798462, 0.9017720222473145, 0.8379175662994385, 0.7784096002578735, 0.7927354574203491, 0.7927354574203491, 0.7927354574203491, 0.752179741859436, 0.872404932975769, 0.7376589775085449, 0.7376589775085449, 0.7957613468170166, 0.7376589775085449, 0.7376589775085449, 0.7376589775085449, 0.7376589775085449, 0.7376589775085449, 0.7376589775085449, 0.9692693315446377, 0.9560593962669373, 0.9650696143507957, 0.9787478912621737, 0.9449195489287376, 0.9274406284093857, 0.944516085088253, 0.9568541720509529, 0.9606360048055649, 0.9531654119491577, 0.9531654119491577, 0.9531654119491577, 0.9531654119491577, 0.9560593962669373, 0.9560593962669373, 0.9560593962669373, 0.9560593962669373, 0.9560593962669373, 0.9560593962669373, 0.9560593962669373, 0.9560593962669373, 0.9560593962669373, 0.9560593962669373, 0.9785708263516426, 0.9596490412950516, 0.9596490412950516, 0.9292492270469666, 0.9719792604446411, 0.9457941427826881, 0.9906335584819317, 0.9560593962669373, 0.9560593962669373, 0.9560593962669373, 0.9560593962669373, 0.9560593962669373, 0.9560593962669373, 0.9999279975891113, 0.9999170303344727, 0.9999170303344727, 0.9987505674362183, 0.9998080730438232, 0.9999346733093262, 0.999957799911499, 0.9999444484710693, 0.9998981952667236, 0.9999072551727295, 0.9999222755432129, 0.9999222755432129, 0.9999222755432129, 0.9999222755432129, 0.9999170303344727, 0.9999170303344727, 0.9999170303344727, 0.9999170303344727, 0.9999170303344727, 0.9999170303344727, 0.9999170303344727, 0.9999170303344727, 0.9999170303344727, 0.9999170303344727, 0.9999170303344727, 0.9998781681060791, 0.7347939908504486, 0.9979121652431786, 0.9525720961391926, 0.9525720961391926, 0.9525720961391926, 0.9525720961391926, 0.9525720961391926, 0.9525720961391926, 0.9494543746113777, 0.9525720961391926, 0.9525720961391926, 0.8167176246643066, 0.9525720961391926, 0.9961757971905172, 0.9970701634883881, 0.9942640662193298, 0.9762396905571222, 0.9762396905571222, 0.9762396905571222, 0.9762396905571222, 0.9762396905571222, 0.9762396905571222, 0.8971862718462944, 0.9762396905571222, 0.9984007739694789, 0.9984007739694789, 0.9557777009904385, 0.9762396905571222, 0.9762396905571222, 0.9762396905571222, 0.8665442913770676, 0.9196141138672829, 0.9956310824491084, 0.9964261907152832, 0.9923930680379272, 0.9979121652431786, 0.4083372950553894]\n",
      "df_group\n",
      "    index  actual  predicted  nr_events  confidence adjusted_values\n",
      "0       0       1   0.981412          1    0.962825                \n",
      "1      15       1   0.599419          1    0.198837                \n",
      "2      45       1   0.978041          1    0.956083                \n",
      "3      77       0   0.037658          1    0.924684                \n",
      "4      83       0   0.035520          1    0.928960                \n",
      "5      92       0   0.446986          1    0.106029                \n",
      "6     100       0   0.934626          1    0.869252                \n",
      "7     110       0   0.220083          1    0.559834                \n",
      "8     113       1   0.965604          1    0.931209                \n",
      "9     149       0   0.967133          1    0.934266                \n",
      "10    185       1   0.999305          1    0.998610                \n",
      "11    213       1   0.946511          1    0.893022                \n",
      "12    243       1   0.205828          1    0.588343                \n",
      "13    250       0   0.096901          1    0.806199                \n",
      "14    286       0   0.560739          1    0.121477                \n",
      "15    322       1   0.714505          1    0.429011                \n",
      "16    325       1   0.987433          1    0.974865                \n",
      "17    346       0   0.015365          1    0.969269                \n",
      "18    382       1   0.999964          1    0.999928                \n",
      "19    408       0   0.132603          1    0.734794                \n",
      "20    444       1   0.295831          1    0.408337                \n",
      "Mean: \n",
      "0.5238095238095238\n",
      "Group length: \n",
      "21\n",
      "Confidences: \n",
      "0     0.962825\n",
      "1     0.198837\n",
      "2     0.956083\n",
      "3     0.924684\n",
      "4     0.928960\n",
      "5     0.106029\n",
      "6     0.869252\n",
      "7     0.559834\n",
      "8     0.931209\n",
      "9     0.934266\n",
      "10    0.998610\n",
      "11    0.893022\n",
      "12    0.588343\n",
      "13    0.806199\n",
      "14    0.121477\n",
      "15    0.429011\n",
      "16    0.974865\n",
      "17    0.969269\n",
      "18    0.999928\n",
      "19    0.734794\n",
      "20    0.408337\n",
      "Name: confidence, dtype: float64\n",
      "0     0.964401\n",
      "1             \n",
      "2             \n",
      "3             \n",
      "4             \n",
      "5             \n",
      "6             \n",
      "7             \n",
      "8             \n",
      "9             \n",
      "10            \n",
      "11            \n",
      "12            \n",
      "13            \n",
      "14            \n",
      "15            \n",
      "16            \n",
      "17            \n",
      "18            \n",
      "19            \n",
      "20            \n",
      "Name: adjusted_values, dtype: object\n",
      "0     0.964401\n",
      "1     0.538843\n",
      "2             \n",
      "3             \n",
      "4             \n",
      "5             \n",
      "6             \n",
      "7             \n",
      "8             \n",
      "9             \n",
      "10            \n",
      "11            \n",
      "12            \n",
      "13            \n",
      "14            \n",
      "15            \n",
      "16            \n",
      "17            \n",
      "18            \n",
      "19            \n",
      "20            \n",
      "Name: adjusted_values, dtype: object\n",
      "0     0.964401\n",
      "1     0.538843\n",
      "2     0.958093\n",
      "3             \n",
      "4             \n",
      "5             \n",
      "6             \n",
      "7             \n",
      "8             \n",
      "9             \n",
      "10            \n",
      "11            \n",
      "12            \n",
      "13            \n",
      "14            \n",
      "15            \n",
      "16            \n",
      "17            \n",
      "18            \n",
      "19            \n",
      "20            \n",
      "Name: adjusted_values, dtype: object\n",
      "0      0.964401\n",
      "1      0.538843\n",
      "2      0.958093\n",
      "3     0.0742731\n",
      "4              \n",
      "5              \n",
      "6              \n",
      "7              \n",
      "8              \n",
      "9              \n",
      "10             \n",
      "11             \n",
      "12             \n",
      "13             \n",
      "14             \n",
      "15             \n",
      "16             \n",
      "17             \n",
      "18             \n",
      "19             \n",
      "20             \n",
      "Name: adjusted_values, dtype: object\n",
      "0      0.964401\n",
      "1      0.538843\n",
      "2      0.958093\n",
      "3     0.0742731\n",
      "4     0.0702077\n",
      "5              \n",
      "6              \n",
      "7              \n",
      "8              \n",
      "9              \n",
      "10             \n",
      "11             \n",
      "12             \n",
      "13             \n",
      "14             \n",
      "15             \n",
      "16             \n",
      "17             \n",
      "18             \n",
      "19             \n",
      "20             \n",
      "Name: adjusted_values, dtype: object\n",
      "0      0.964401\n",
      "1      0.538843\n",
      "2      0.958093\n",
      "3     0.0742731\n",
      "4     0.0702077\n",
      "5      0.515664\n",
      "6              \n",
      "7              \n",
      "8              \n",
      "9              \n",
      "10             \n",
      "11             \n",
      "12             \n",
      "13             \n",
      "14             \n",
      "15             \n",
      "16             \n",
      "17             \n",
      "18             \n",
      "19             \n",
      "20             \n",
      "Name: adjusted_values, dtype: object\n",
      "0      0.964401\n",
      "1      0.538843\n",
      "2      0.958093\n",
      "3     0.0742731\n",
      "4     0.0702077\n",
      "5      0.515664\n",
      "6      0.880913\n",
      "7              \n",
      "8              \n",
      "9              \n",
      "10             \n",
      "11             \n",
      "12             \n",
      "13             \n",
      "14             \n",
      "15             \n",
      "16             \n",
      "17             \n",
      "18             \n",
      "19             \n",
      "20             \n",
      "Name: adjusted_values, dtype: object\n",
      "0      0.964401\n",
      "1      0.538843\n",
      "2      0.958093\n",
      "3     0.0742731\n",
      "4     0.0702077\n",
      "5      0.515664\n",
      "6      0.880913\n",
      "7      0.353773\n",
      "8              \n",
      "9              \n",
      "10             \n",
      "11             \n",
      "12             \n",
      "13             \n",
      "14             \n",
      "15             \n",
      "16             \n",
      "17             \n",
      "18             \n",
      "19             \n",
      "20             \n",
      "Name: adjusted_values, dtype: object\n",
      "0      0.964401\n",
      "1      0.538843\n",
      "2      0.958093\n",
      "3     0.0742731\n",
      "4     0.0702077\n",
      "5      0.515664\n",
      "6      0.880913\n",
      "7      0.353773\n",
      "8      0.935213\n",
      "9              \n",
      "10             \n",
      "11             \n",
      "12             \n",
      "13             \n",
      "14             \n",
      "15             \n",
      "16             \n",
      "17             \n",
      "18             \n",
      "19             \n",
      "20             \n",
      "Name: adjusted_values, dtype: object\n",
      "0      0.964401\n",
      "1      0.538843\n",
      "2      0.958093\n",
      "3     0.0742731\n",
      "4     0.0702077\n",
      "5      0.515664\n",
      "6      0.880913\n",
      "7      0.353773\n",
      "8      0.935213\n",
      "9      0.937991\n",
      "10             \n",
      "11             \n",
      "12             \n",
      "13             \n",
      "14             \n",
      "15             \n",
      "16             \n",
      "17             \n",
      "18             \n",
      "19             \n",
      "20             \n",
      "Name: adjusted_values, dtype: object\n",
      "0      0.964401\n",
      "1      0.538843\n",
      "2      0.958093\n",
      "3     0.0742731\n",
      "4     0.0702077\n",
      "5      0.515664\n",
      "6      0.880913\n",
      "7      0.353773\n",
      "8      0.935213\n",
      "9      0.937991\n",
      "10     0.998644\n",
      "11             \n",
      "12             \n",
      "13             \n",
      "14             \n",
      "15             \n",
      "16             \n",
      "17             \n",
      "18             \n",
      "19             \n",
      "20             \n",
      "Name: adjusted_values, dtype: object\n",
      "0      0.964401\n",
      "1      0.538843\n",
      "2      0.958093\n",
      "3     0.0742731\n",
      "4     0.0702077\n",
      "5      0.515664\n",
      "6      0.880913\n",
      "7      0.353773\n",
      "8      0.935213\n",
      "9      0.937991\n",
      "10     0.998644\n",
      "11     0.901291\n",
      "12             \n",
      "13             \n",
      "14             \n",
      "15             \n",
      "16             \n",
      "17             \n",
      "18             \n",
      "19             \n",
      "20             \n",
      "Name: adjusted_values, dtype: object\n",
      "0      0.964401\n",
      "1      0.538843\n",
      "2      0.958093\n",
      "3     0.0742731\n",
      "4     0.0702077\n",
      "5      0.515664\n",
      "6      0.880913\n",
      "7      0.353773\n",
      "8      0.935213\n",
      "9      0.937991\n",
      "10     0.998644\n",
      "11     0.901291\n",
      "12     0.336728\n",
      "13             \n",
      "14             \n",
      "15             \n",
      "16             \n",
      "17             \n",
      "18             \n",
      "19             \n",
      "20             \n",
      "Name: adjusted_values, dtype: object\n",
      "0      0.964401\n",
      "1      0.538843\n",
      "2      0.958093\n",
      "3     0.0742731\n",
      "4     0.0702077\n",
      "5      0.515664\n",
      "6      0.880913\n",
      "7      0.353773\n",
      "8      0.935213\n",
      "9      0.937991\n",
      "10     0.998644\n",
      "11     0.901291\n",
      "12     0.336728\n",
      "13     0.179636\n",
      "14             \n",
      "15             \n",
      "16             \n",
      "17             \n",
      "18             \n",
      "19             \n",
      "20             \n",
      "Name: adjusted_values, dtype: object\n",
      "0      0.964401\n",
      "1      0.538843\n",
      "2      0.958093\n",
      "3     0.0742731\n",
      "4     0.0702077\n",
      "5      0.515664\n",
      "6      0.880913\n",
      "7      0.353773\n",
      "8      0.935213\n",
      "9      0.937991\n",
      "10     0.998644\n",
      "11     0.901291\n",
      "12     0.336728\n",
      "13     0.179636\n",
      "14     0.528296\n",
      "15             \n",
      "16             \n",
      "17             \n",
      "18             \n",
      "19             \n",
      "20             \n",
      "Name: adjusted_values, dtype: object\n",
      "0      0.964401\n",
      "1      0.538843\n",
      "2      0.958093\n",
      "3     0.0742731\n",
      "4     0.0702077\n",
      "5      0.515664\n",
      "6      0.880913\n",
      "7      0.353773\n",
      "8      0.935213\n",
      "9      0.937991\n",
      "10     0.998644\n",
      "11     0.901291\n",
      "12     0.336728\n",
      "13     0.179636\n",
      "14     0.528296\n",
      "15      0.60562\n",
      "16             \n",
      "17             \n",
      "18             \n",
      "19             \n",
      "20             \n",
      "Name: adjusted_values, dtype: object\n",
      "0      0.964401\n",
      "1      0.538843\n",
      "2      0.958093\n",
      "3     0.0742731\n",
      "4     0.0702077\n",
      "5      0.515664\n",
      "6      0.880913\n",
      "7      0.353773\n",
      "8      0.935213\n",
      "9      0.937991\n",
      "10     0.998644\n",
      "11     0.901291\n",
      "12     0.336728\n",
      "13     0.179636\n",
      "14     0.528296\n",
      "15      0.60562\n",
      "16      0.97578\n",
      "17             \n",
      "18             \n",
      "19             \n",
      "20             \n",
      "Name: adjusted_values, dtype: object\n",
      "0      0.964401\n",
      "1      0.538843\n",
      "2      0.958093\n",
      "3     0.0742731\n",
      "4     0.0702077\n",
      "5      0.515664\n",
      "6      0.880913\n",
      "7      0.353773\n",
      "8      0.935213\n",
      "9      0.937991\n",
      "10     0.998644\n",
      "11     0.901291\n",
      "12     0.336728\n",
      "13     0.179636\n",
      "14     0.528296\n",
      "15      0.60562\n",
      "16      0.97578\n",
      "17    0.0309902\n",
      "18             \n",
      "19             \n",
      "20             \n",
      "Name: adjusted_values, dtype: object\n",
      "0      0.964401\n",
      "1      0.538843\n",
      "2      0.958093\n",
      "3     0.0742731\n",
      "4     0.0702077\n",
      "5      0.515664\n",
      "6      0.880913\n",
      "7      0.353773\n",
      "8      0.935213\n",
      "9      0.937991\n",
      "10     0.998644\n",
      "11     0.901291\n",
      "12     0.336728\n",
      "13     0.179636\n",
      "14     0.528296\n",
      "15      0.60562\n",
      "16      0.97578\n",
      "17    0.0309902\n",
      "18      0.99993\n",
      "19             \n",
      "20             \n",
      "Name: adjusted_values, dtype: object\n",
      "0      0.964401\n",
      "1      0.538843\n",
      "2      0.958093\n",
      "3     0.0742731\n",
      "4     0.0702077\n",
      "5      0.515664\n",
      "6      0.880913\n",
      "7      0.353773\n",
      "8      0.935213\n",
      "9      0.937991\n",
      "10     0.998644\n",
      "11     0.901291\n",
      "12     0.336728\n",
      "13     0.179636\n",
      "14     0.528296\n",
      "15      0.60562\n",
      "16      0.97578\n",
      "17    0.0309902\n",
      "18      0.99993\n",
      "19     0.236353\n",
      "20             \n",
      "Name: adjusted_values, dtype: object\n",
      "0      0.964401\n",
      "1      0.538843\n",
      "2      0.958093\n",
      "3     0.0742731\n",
      "4     0.0702077\n",
      "5      0.515664\n",
      "6      0.880913\n",
      "7      0.353773\n",
      "8      0.935213\n",
      "9      0.937991\n",
      "10     0.998644\n",
      "11     0.901291\n",
      "12     0.336728\n",
      "13     0.179636\n",
      "14     0.528296\n",
      "15      0.60562\n",
      "16      0.97578\n",
      "17    0.0309902\n",
      "18      0.99993\n",
      "19     0.236353\n",
      "20     0.430718\n",
      "Name: adjusted_values, dtype: object\n",
      "actual\n",
      "predicted\n",
      "nr_events\n",
      "confidence\n",
      "adjusted_values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julia\\PyCharm_projects\\experiments\\experiments.py:295: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_group.adjusted_values[index] = adjust_with_regression_to_the_mean(df_group.predicted[index], mean, df_group.confidence[index])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fout' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\PyCharm_projects\\experiments\\experiments.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m             \u001b[1;31m# writing roc/auc score based on actual vs predicted results (sorted by number of events)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m             fout.write(\"%s;%s;%s;%s;%s;%s;%s\\n\" % (dataset_name, method_name, cls_method, nr_events, -1, \"auc\",\n\u001b[0m\u001b[0;32m    304\u001b[0m                                                    roc_auc_score(group.actual, group.predicted)))\n\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fout' is not defined"
     ]
    }
   ],
   "source": [
    "%run experiments/experiments.py \"bpic2011\" \"output\" \"results\" \"single\" \"laststate\" \"xgboost\" \"1\" \"10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08293c14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
